{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Lets-prepare-our-data\" data-toc-modified-id=\"Lets-prepare-our-data-1\">Lets prepare our data</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-example-by-column\" data-toc-modified-id=\"One-example-by-column-1.1\">One example by column</a></span></li><li><span><a href=\"#Flattening-images\" data-toc-modified-id=\"Flattening-images-1.2\">Flattening images</a></span></li><li><span><a href=\"#Standardize-data-to-have-feature-values-between-0-and-1\" data-toc-modified-id=\"Standardize-data-to-have-feature-values-between-0-and-1-1.3\">Standardize data to have feature values between 0 and 1</a></span></li><li><span><a href=\"#Check-the-shapes\" data-toc-modified-id=\"Check-the-shapes-1.4\">Check the shapes</a></span></li><li><span><a href=\"#One-hot-encoding-the-labels-vectors\" data-toc-modified-id=\"One-hot-encoding-the-labels-vectors-1.5\">One hot encoding the labels vectors</a></span></li><li><span><a href=\"#Final-check-of-shapes\" data-toc-modified-id=\"Final-check-of-shapes-1.6\">Final check of shapes</a></span></li></ul></li><li><span><a href=\"#Defining-the-model,-i.e.-the-NN-architecture\" data-toc-modified-id=\"Defining-the-model,-i.e.-the-NN-architecture-2\">Defining the model, i.e. the NN architecture</a></span></li><li><span><a href=\"#Initializing-the-parameters\" data-toc-modified-id=\"Initializing-the-parameters-3\">Initializing the parameters</a></span></li><li><span><a href=\"#Defining-activation-functions\" data-toc-modified-id=\"Defining-activation-functions-4\">Defining activation functions</a></span></li><li><span><a href=\"#Forward-Propagation\" data-toc-modified-id=\"Forward-Propagation-5\">Forward Propagation</a></span></li><li><span><a href=\"#Computing-the-current-Cost\" data-toc-modified-id=\"Computing-the-current-Cost-6\">Computing the current Cost</a></span></li><li><span><a href=\"#Backpropagation\" data-toc-modified-id=\"Backpropagation-7\">Backpropagation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deep Neural Network\n",
    "<hr>\n",
    "\n",
    "A DNN can be decomposed as the following sequence of operations:\n",
    "* Input Data\n",
    "* Forward Propagation to obtain an Output Data\n",
    "* Evaluate Output Data (compute current Cost)\n",
    "* Given current Cost, do Back-propagation to update weights\n",
    "* Repeat from beggining with updated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run shapesdata.ipynb\n",
    "\n",
    "# Loading the data (circle, square and triangle drawings)\n",
    "train_x_orig, train_y_orig, test_x_orig, test_y_orig, _, _ = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a ['triangle']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a drawing and its label\n",
    "print_img(train_x_orig, train_y_orig, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_orig: (270, 28, 28, 3)\n",
      "train_y_orig: (270, 1)\n",
      "test_x_orig: (30, 28, 28, 3)\n",
      "test_y_orig: (30, 1)\n"
     ]
    }
   ],
   "source": [
    "# Lets see what are the shapes of our variables\n",
    "print(\"train_x_orig: {}\".format(train_x_orig.shape))\n",
    "print(\"train_y_orig: {}\".format(train_y_orig.shape))\n",
    "print(\"test_x_orig: {}\".format(test_x_orig.shape))\n",
    "print(\"test_y_orig: {}\".format(test_y_orig.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets prepare our data\n",
    "\n",
    "### One example by column\n",
    "We can arrange our example either by rows or by columns. Here we choose to arrange them by columns.\n",
    "\n",
    "### Flattening images\n",
    "First, we need to flatten our images, since they are actually arrays and we want them to be vectors. Our **train_x_orig** and **test_x_orig** variables are arrays with shape **(210, 28, 28, 3)**, where the first number stands for the number of examples we have in the set and the remaining three number are a single image array. We want them to be arrays of shape **(28\\*28\\*3, 210)**, so we use numpy's reshape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data to have feature values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x_flatten/255\n",
    "test_x = test_x_flatten/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x: (2352, 270)\n",
      "test_x: (2352, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"test_x: {}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding the labels vectors\n",
    "Our **train_y_orig** and **test_y_orig** variables are arrays with shape **(210, 1)**, i.e. column vectors, and to each example there is an associate class indicated by a string, i.e. 'circle'. However, we want this classes to be indicated by numbers and the best way to do that is by a process called **one hot encoding**:\n",
    "* We define a vector whose each component corresponds to a class, and we indicate that our example belongs to a certain class by filling this vector with zeros except for the corresponding class component, which we fill with 1.\n",
    "* To each example, then, we associate one of this vectors.\n",
    "\n",
    "After one hot encoding train_y_orig and test_y_orig we should have labels vectors **train_y** and **test_y** of shape **(3, 210)** and **(3, 90)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencode(y):\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    one_hot_y = np.zeros((y.shape[0], len(classes)))\n",
    "    \n",
    "    for i, item in enumerate(y):\n",
    "#         print(i, item)\n",
    "        one_hot_y[i] = item == classes\n",
    "\n",
    "    one_hot_y = one_hot_y.T\n",
    "    \n",
    "    return one_hot_y\n",
    "\n",
    "train_y = onehotencode(train_y_orig)\n",
    "test_y = onehotencode(test_y_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final check of shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x: (2352, 270)\n",
      "train_y: (3, 270)\n",
      "test_x: (2352, 30)\n",
      "test_y: (3, 30)\n"
     ]
    }
   ],
   "source": [
    "# Lets see what are the new shapes of our variables\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x: {}\".format(test_x.shape))\n",
    "print(\"test_y: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model, i.e. the NN architecture\n",
    "<hr>\n",
    "\n",
    "* Lets denote the number of features of an example by **n_x**\n",
    "* Lets denote the number of classes we can classify to by **C**\n",
    "* Lets denote the number of exampels in the training set by **M**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = train_x.shape[1]                   # Number of examples\n",
    "n_x = train_x.shape[0]                 # Number of features\n",
    "C = 3                                  # Number of classes\n",
    "hidden_layers = [20, 7, 5]             # Number of hidden layers and their respective size\n",
    "\n",
    "layer_dims = [n_x, *hidden_layers, C] # Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "                  including the dimension of the input and the output\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2/layer_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "# parameters = initialize_parameters(layer_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \n",
    "    s = 1/(1+np.exp(-x))\n",
    "#     cache = x\n",
    "    \n",
    "    return s\n",
    "\n",
    "def relu(x):\n",
    "    e = 0.01\n",
    "    r = np.maximum(e*x,x)\n",
    "#     cache = x\n",
    "    \n",
    "    return r\n",
    "\n",
    "def softmax(x):\n",
    "    \n",
    "    x_exp = np.exp(x)\n",
    "\n",
    "    x_sum = np.sum(x_exp, axis = 0, keepdims = True)\n",
    "    \n",
    "    s = x_exp/x_sum\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "We know that when going from the layer $l-1$ to the layer $l$ we do the following:\n",
    "\\begin{equation}\n",
    "    Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]},\n",
    "\\end{equation}\n",
    "then\n",
    "\\begin{equation}\n",
    "    A^{[l]} = g^{[l]}(Z^{[l]}),\n",
    "\\end{equation}\n",
    "so let's write a code to perform this steps, bearing in mind that we will use them inside the main iteration loop.\n",
    "\n",
    "* Lets denote $A^{[l-1]}$ by **A_prev**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_forward(A_prev, W, b, activation_function = \"relu\"):\n",
    "    \"\"\"\n",
    "    Implement a layer's forward propagation step.\n",
    "\n",
    "    Arguments:\n",
    "        A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "        W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "        b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "        Z -- the input of the activation function, also called pre-activation parameter \n",
    "        cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = W @ A_prev + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A_prev.shape[1])) # This line checks the dimensions of Z\n",
    "    \n",
    "    if activation_function == 'relu':\n",
    "        A = relu(Z)\n",
    "        \n",
    "    if activation_function == 'sigmoid':\n",
    "        A = sigmoid(Z)\n",
    "        \n",
    "    if activation_function == 'softmax':\n",
    "        A = softmax(Z)\n",
    "        \n",
    "    assert (A.shape == Z.shape) # This line checks the dimensions of A, which should be the same as of Z\n",
    "\n",
    "        \n",
    "    cache = (A_prev, W, b, Z)\n",
    "    \n",
    "#     return Z, cache\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29969313, 0.29873118],\n",
       "       [0.33790306, 0.34362265],\n",
       "       [0.3624038 , 0.35764616]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function\n",
    "A = np.array([[.1,.2],[.5,.4]])\n",
    "W = np.array([[.2,.3],[.4,.3],[.1, .3]])\n",
    "b = np.array([[.1,.1],[.2,.2],[.3,.3]])\n",
    "\n",
    "test ,_ =step_forward(A, W, b, 'softmax')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "    caches = []\n",
    "    \n",
    "    A = X\n",
    "    L = len(parameters) // 2     # number of layers in the neural network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        W = parameters[\"W\"+str(l)]\n",
    "        b = parameters[\"b\"+str(l)]\n",
    "        \n",
    "        A, cache = step_forward(A_prev, W, b, 'relu')\n",
    "#         print(A.T[l])\n",
    "        caches.append(cache)\n",
    "        \n",
    "    A_prev = A\n",
    "    W = parameters[\"W\"+str(L)]\n",
    "    b = parameters[\"b\"+str(L)]\n",
    "    \n",
    "    AL, cache = step_forward(A_prev, W, b, 'softmax')\n",
    "#     print(AL.T[l])\n",
    "    caches.append(cache)\n",
    "        \n",
    "    assert(AL.shape == (C, X.shape[1]))\n",
    "                \n",
    "    return AL, caches\n",
    "\n",
    "# AL, caches = forward_propagation(train_x, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AL.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the current Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    a = Y*np.log(AL)\n",
    "    \n",
    "    loss = np.sum(a, axis = 0)\n",
    "    cost = (-1)*(1/M)*np.sum(loss)\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost = compute_cost(AL, train_y)\n",
    "# cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_derivative(z):\n",
    "    \n",
    "    x = softmax(z)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.multiply(x,(1-x))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    x = sigmoid(z)\n",
    "    return np.multiply(x,(1-x))\n",
    "\n",
    "def relu_derivative(z):\n",
    "    x = np.zeros(z.shape)\n",
    "    x[z > 0] = 1\n",
    "    x[z <= 0] = 0.01\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_step(dA, A_prev, W, b, Z, activation_function = \"relu\"):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    \n",
    "    M = A_prev.shape[1]\n",
    "    \n",
    "    if activation_function == 'relu':\n",
    "        dZ = np.multiply(dA, relu_derivative(Z))\n",
    "        \n",
    "    if activation_function == 'sigmoid': \n",
    "        dZ = np.multiply(dA, sigmoid_derivative(Z))\n",
    "        \n",
    "    if activation_function == 'softmax':\n",
    "        dZ = np.multiply(dA,softmax(Z)) - np.diag(dA.T @ softmax(Z))*softmax(Z)\n",
    "        \n",
    "    dW = (dZ @ A_prev.T)\n",
    "    \n",
    "    db = np.sum(dZ, axis = 1, keepdims = True)\n",
    "    \n",
    "    dA_prev = W.T @ dZ\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    M = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "#     dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    dAL = (-Y/AL)/M\n",
    "        \n",
    "    dA = dAL\n",
    "    \n",
    "    A_prev, W, b, Z = caches[L-1]\n",
    "    \n",
    "    dA_prev, dW, db = backward_step(dA, A_prev, W, b, Z, 'softmax')\n",
    "    \n",
    "    grads[\"dA\" + str(L-1)] = dA_prev\n",
    "    grads[\"dW\" + str(L)] = dW\n",
    "    grads[\"db\" + str(L)] = db\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(0, L-1)):   # Note that the first value \"l\" takes is L-2 \n",
    "        \n",
    "        dA = grads[\"dA\" + str(l+1)]  # Note that the first index used is \"l+1\" = L-1, whish follows the L we used\n",
    "        A_prev, W, b, Z = caches[l]\n",
    "    \n",
    "        dA_prev, dW, db = backward_step(dA, A_prev, W, b, Z, 'relu')\n",
    "\n",
    "        grads[\"dA\" + str(l)] = dA_prev\n",
    "        grads[\"dW\" + str(l+1)] = dW\n",
    "        grads[\"db\" + str(l+1)] = db\n",
    "\n",
    "    return grads\n",
    "\n",
    "# grads = backward_propagation(AL, train_y, caches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\" + str(l+1)]\n",
    "    return parameters\n",
    "\n",
    "# parameters = update_parameters(parameters, grads, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(X, Y, dev_x, dev_y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "    train_errors = []                         # keep track of train error\n",
    "    test_errors = []                          # keep track of train error\n",
    "    \n",
    "    # Parameters initialization. (â‰ˆ 1 line of code)\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = forward_propagation(X, parameters)\n",
    "        \n",
    "        dev_AL, _ = forward_propagation(dev_x, parameters)\n",
    "        \n",
    "        # Compute cost.\n",
    "        train_error = compute_cost(AL, Y)\n",
    "        \n",
    "        test_error = compute_cost(dev_AL, dev_y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = backward_propagation(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, train_error))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            train_errors.append(train_error)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            test_errors.append(test_error)\n",
    "        \n",
    "    # plot the cost\n",
    "#     plt.plot(np.squeeze(train_errors))\n",
    "    plt.plot(np.squeeze(test_errors))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    Yhat, _ = forward_propagation(X, parameters)\n",
    "    pred = np.zeros(Yhat.shape).T\n",
    "    for m in range(Yhat.shape[1]):\n",
    "        pred[m][np.argmax(Yhat.T[m], axis = 0)] = 1\n",
    "    return pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_right(train_y, train_pred):\n",
    "    prod = train_y*train_pred\n",
    "    \n",
    "#     es = train_pred == train_y\n",
    "    \n",
    "    ans = np.logical_and(*(train_pred == train_y))\n",
    "    ans = ans[np.newaxis, :]\n",
    "    \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(X, y_true, parameters):\n",
    "    pred = predict(X, parameters)\n",
    "    isright = check_right(y_true, pred)\n",
    "    a = np.unique(isright, return_counts=True)\n",
    "    percen_wrong = a[1][0]/np.sum(a[1])\n",
    "    percen_right = a[1][1]/np.sum(a[1])\n",
    "    return percen_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.071551\n",
      "Cost after iteration 1000: 0.961509\n",
      "Cost after iteration 2000: 0.570091\n",
      "Cost after iteration 3000: 0.495948\n",
      "Cost after iteration 4000: 0.442865\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-372b71ca93cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     print_cost=True)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-37405b7dbe92>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(X, y_true, parameters)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpercen_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpercen_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpercen_right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "M = train_x.shape[1]                     # Number of examples\n",
    "n_x = train_x.shape[0]                   # Number of features\n",
    "C = 3                                    # Number of classes\n",
    "hidden_layers = [150, 100, 50]              # Number of hidden layers and their respective size\n",
    "\n",
    "layer_dims = [n_x, *hidden_layers, C] # Neural Network Architecture\n",
    "\n",
    "num_iter = 5000\n",
    "\n",
    "test_errors = []\n",
    "\n",
    "trained_parameters = deep_model(\n",
    "    train_x, \n",
    "    train_y, \n",
    "    test_x,\n",
    "    test_y,\n",
    "    layer_dims,\n",
    "    learning_rate = 0.003, \n",
    "    num_iterations = num_iter, \n",
    "    print_cost=True)\n",
    "\n",
    "acc_train = get_score(train_x, train_y, trained_parameters)\n",
    "acc_test = get_score(test_x, test_y, trained_parameters)\n",
    "\n",
    "print(\"With {} iteration, the model achieved a {}% accuracy on the train set.\".format(num_iter, acc_train*100))\n",
    "print(\"With {} iteration, the model achieved a {}% accuracy on the test set.\".format(num_iter, acc_test*100))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
